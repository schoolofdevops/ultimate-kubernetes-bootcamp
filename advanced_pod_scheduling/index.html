<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  
  <link rel="shortcut icon" href="../img/favicon.ico">
  <title>Advanced Pod Scheduling - Ultimate Kubernetes Bootcamp</title>
  <link href='https://fonts.googleapis.com/css?family=Lato:400,700|Roboto+Slab:400,700|Inconsolata:400,700' rel='stylesheet' type='text/css'>

  <link rel="stylesheet" href="../css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../css/theme_extra.css" type="text/css" />
  <link rel="stylesheet" href="../css/highlight.css">
  
  <script>
    // Current page data
    var mkdocs_page_name = "Advanced Pod Scheduling";
    var mkdocs_page_input_path = "advanced_pod_scheduling.md";
    var mkdocs_page_url = "/advanced_pod_scheduling/";
  </script>
  
  <script src="../js/jquery-2.1.1.min.js"></script>
  <script src="../js/modernizr-2.8.3.min.js"></script>
  <script type="text/javascript" src="../js/highlight.pack.js"></script> 
  
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
      <div class="wy-side-nav-search">
        <a href=".." class="icon icon-home"> Ultimate Kubernetes Bootcamp</a>
        <div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
	<ul class="current">
	  
          
            <li class="toctree-l1">
		
    <a class="" href="..">Home</a>
	    </li>
          
            <li class="toctree-l1">
		
    <span class="caption-text">Setup</span>
    <ul class="subnav">
                <li class="">
                    
    <a class="" href="../minikube/">Using minikube to setup single node environment</a>
                </li>
                <li class="">
                    
    <a class="" href="../2_kube_cluster_vagrant/">Provisioning VMs with Vagrant</a>
                </li>
                <li class="">
                    
    <a class="" href="../3_install_kubernetes/">Setup Kubernetes Cluster</a>
                </li>
                <li class="">
                    
    <a class="" href="../kube_visualizer/">Kuberentes Visualizer</a>
                </li>
    </ul>
	    </li>
          
            <li class="toctree-l1">
		
    <span class="caption-text">Kubernetes Fundamentals</span>
    <ul class="subnav">
                <li class="">
                    
    <a class="" href="../5-vote-deploying_pods/">Launching Pods</a>
                </li>
                <li class="">
                    
    <a class="" href="../replication/">Making application highly available</a>
                </li>
                <li class="">
                    
    <a class="" href="../7-vote-exposing_app_with_service/">Publishing appliaction and Service Discovery</a>
                </li>
                <li class="">
                    
    <a class="" href="../6-vote-kubernetes_deployment/">Defining Update Strategy</a>
                </li>
                <li class="">
                    
    <a class="" href="../11_deploying_sample_app/">Mini Project</a>
                </li>
                <li class="">
                    
    <a class="" href="../9-vote-configmaps_and_secrets/">Managing Configurations and Secrets</a>
                </li>
                <li class="">
                    
    <a class="" href="../vote-persistent-volumes/">Making Data Persist</a>
                </li>
    </ul>
	    </li>
          
            <li class="toctree-l1">
		
    <span class="caption-text">Advanced Kubernetes</span>
    <ul class="subnav">
                <li class="">
                    
    <a class="" href="../kubespray-prereqs/">Kubespray lab setup with Vagrant</a>
                </li>
                <li class="">
                    
    <a class="" href="../cluster_setup_kubespray/">Production grade setup with Kubespray</a>
                </li>
                <li class="">
                    
    <a class="" href="../configuring_authentication_and_authorization/">Authentication and Authorization (RBAC)</a>
                </li>
                <li class=" current">
                    
    <a class="current" href="./">Advanced Pod Scheduling</a>
    <ul class="subnav">
            
    <li class="toctree-l3"><a href="#advanced-pod-scheduling">Advanced Pod Scheduling</a></li>
    
        <ul>
        
            <li><a class="toctree-l4" href="#using-node-selectors">Using Node Selectors</a></li>
        
            <li><a class="toctree-l4" href="#defining-affinity-and-anti-affinity">Defining  affinity and anti-affinity</a></li>
        
            <li><a class="toctree-l4" href="#taints-and-tolerations">Taints and tolerations</a></li>
        
        </ul>
    

    </ul>
                </li>
                <li class="">
                    
    <a class="" href="../pod-adv-specs/">Pod Resource and Security Specs</a>
                </li>
                <li class="">
                    
    <a class="" href="../pods-health-probes/">Adding health checks with Probes</a>
                </li>
                <li class="">
                    
    <a class="" href="../ingress/">Application Routing with Ingress Controllers</a>
                </li>
                <li class="">
                    
    <a class="" href="../10_kubernetes_autoscaling/">Auto Scaling Capacity with HPA</a>
                </li>
                <li class="">
                    
    <a class="" href="../13_redis_statefulset/">Creating Replicated Redis Cluster with Statefulsets</a>
                </li>
                <li class="">
                    
    <a class="" href="../network_policies/">Access Control with Network Policies</a>
                </li>
                <li class="">
                    
    <a class="" href="../cluster-administration/">Cluster Administration</a>
                </li>
    </ul>
	    </li>
          
            <li class="toctree-l1">
		
    <span class="caption-text">Additional Topics</span>
    <ul class="subnav">
                <li class="">
                    
    <a class="" href="../vote-deployement_strategies/">Building Deployment Strategies</a>
                </li>
                <li class="">
                    
    <a class="" href="../12_troubleshooting/">Troubleshooting Tips</a>
                </li>
                <li class="">
                    
    <a class="" href="../logging/">Logging</a>
                </li>
    </ul>
	    </li>
          
            <li class="toctree-l1">
		
    <span class="caption-text">References</span>
    <ul class="subnav">
                <li class="">
                    
    <a class="" href="../rbac-resource-group-mapping/">RBAC apiGroups to Resource Mapping</a>
                </li>
    </ul>
	    </li>
          
        </ul>
      </div>
      &nbsp;
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
        <a href="..">Ultimate Kubernetes Bootcamp</a>
      </nav>

      
      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="..">Docs</a> &raquo;</li>
    
      
        
          <li>Advanced Kubernetes &raquo;</li>
        
      
    
    <li>Advanced Pod Scheduling</li>
    <li class="wy-breadcrumbs-aside">
      
    </li>
  </ul>
  <hr/>
</div>
          <div role="main">
            <div class="section">
              
                <h1 id="advanced-pod-scheduling">Advanced Pod Scheduling</h1>
<p>In the Kubernetes bootcamp training, we have seen how to create a pod and and some basic pod configurations to go with it. But this chapter explains some advanced topics related to pod scheduling.</p>
<p>From the <a href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.11/#pod-v1-core">api document for version 1.11</a> following are the pod specs which are relevant from scheduling perspective.</p>
<ul>
<li>nodeSelector</li>
<li>nodeName</li>
<li>affinity</li>
<li>schedulerName</li>
<li>tolerations</li>
</ul>
<h2 id="using-node-selectors">Using Node Selectors</h2>
<pre><code>kubectl get nodes --show-labels

kubectl label nodes &lt;node-name&gt; zone=aaa

kubectl get nodes --show-labels

</code></pre>

<p>e.g.</p>
<pre><code>kubectl label nodes node1 zone=bbb
kubectl label nodes node2 zone=bbb
kubectl label nodes node3 zone=aaa
kubectl label nodes node4 zone=aaa
kubectl get nodes --show-labels
</code></pre>

<p>[sample output]</p>
<pre><code>NAME      STATUS    ROLES         AGE       VERSION   LABELS
node1     Ready     master,node   22h       v1.10.4   beta.kubernetes.io/arch=amd64,beta.kubernetes.io/os=linux,kubernetes.io/hostname=node1,node-role.kubernetes.io/master=true,node-role.kubernetes.io/node=true,zone=bbb
node2     Ready     master,node   22h       v1.10.4   beta.kubernetes.io/arch=amd64,beta.kubernetes.io/os=linux,kubernetes.io/hostname=node2,node-role.kubernetes.io/master=true,node-role.kubernetes.io/node=true,zone=bbb
node3     Ready     node          22h       v1.10.4   beta.kubernetes.io/arch=amd64,beta.kubernetes.io/os=linux,kubernetes.io/hostname=node3,node-role.kubernetes.io/node=true,zone=aaa
node4     Ready     node          21h       v1.10.4   beta.kubernetes.io/arch=amd64,beta.kubernetes.io/os=linux,kubernetes.io/hostname=node4,node-role.kubernetes.io/node=true,zone=aaa
</code></pre>

<p>Check how the pods are distributed on the nodes using the following command,</p>
<pre><code>kubectl get pods -o wide --selector=&quot;role=vote&quot;
NAME                    READY     STATUS    RESTARTS   AGE       IP               NODE
vote-5d88d47fc8-6rflg   1/1       Running   0          1m        10.233.75.9      node2
vote-5d88d47fc8-gbzbq   1/1       Running   0          1h        10.233.74.76     node4
vote-5d88d47fc8-q4vj6   1/1       Running   0          1h        10.233.102.133   node1
vote-5d88d47fc8-znd2z   1/1       Running   0          1m        10.233.71.20     node3
</code></pre>

<p>From the above output, you could see that the pods running <strong>vote</strong> app are currently equally distributed.
Now, update pod definition to make it schedule only on nodes in zone <strong>bbb</strong></p>
<p><code>file: k8s-code/pods/vote-pod.yml</code></p>
<pre><code>
....

template:
...
  spec:
    containers:
      - name: app
        image: schoolofdevops/vote:v1
        ports:
          - containerPort: 80
            protocol: TCP
    nodeSelector:
      zone: 'bbb'
</code></pre>

<p>For this change, pod needs to be re created.</p>
<pre><code>kubectl apply -f vote-pod.yml
</code></pre>

<p>You would notice that, the moment you make that change, a new rollout kicks off, which will start redistributing the pods, now following the <strong>nodeSelector</strong> constraint that you added.</p>
<p>Watch the output of the following command</p>
<pre><code>
watch kubectl get pods -o wide --selector=&quot;role=vote&quot;

</code></pre>

<p>You will see the following while it transitions</p>
<pre><code>
NAME                        READY     STATUS              RESTARTS   AGE       IP               NODE
pod/vote-5d88d47fc8-6rflg   0/1       Terminating         0          5m        10.233.75.9      node2
pod/vote-5d88d47fc8-gbzbq   0/1       Terminating         0          1h        10.233.74.76     node4
pod/vote-5d88d47fc8-q4vj6   0/1       Terminating         0          1h        10.233.102.133   node1
pod/vote-67d7dd8f89-2w5wl   1/1       Running             0          44s       10.233.75.10     node2
pod/vote-67d7dd8f89-gm6bq   0/1       ContainerCreating   0          2s        &lt;none&gt;           node2
pod/vote-67d7dd8f89-w87n9   1/1       Running             0          44s       10.233.102.134   node1
pod/vote-67d7dd8f89-xccl8   1/1       Running             0          44s       10.233.102.135   node1

</code></pre>

<p>and after the rollout completes,</p>
<pre><code>
NAME                    READY     STATUS    RESTARTS   AGE       IP               NODE
vote-67d7dd8f89-2w5wl   1/1       Running   0          2m        10.233.75.10     node2
vote-67d7dd8f89-gm6bq   1/1       Running   0          1m        10.233.75.11     node2
vote-67d7dd8f89-w87n9   1/1       Running   0          2m        10.233.102.134   node1
vote-67d7dd8f89-xccl8   1/1       Running   0          2m        10.233.102.135   node1

</code></pre>

<h4 id="exercise">Exercise</h4>
<p>Just like <strong>nodeSelector</strong> above, you could enforce a pod to run on a specific node using <strong>nodeName</strong>. Try using that property to run all pods for results application on <strong>node3</strong></p>
<h2 id="defining-affinity-and-anti-affinity">Defining  affinity and anti-affinity</h2>
<p>We have discussed about scheduling a pod on a particular node using <strong>NodeSelector</strong>, but using node selector is a hard condition. If the condition is not met, the pod cannot be scheduled. Node/Pod affinity and anti-affinity solves this issue by introducing soft and hard conditions.</p>
<ul>
<li>required</li>
<li>
<p>preferred</p>
</li>
<li>
<p>DuringScheduling</p>
</li>
<li>DuringExecution</li>
</ul>
<p>Operators</p>
<ul>
<li>In</li>
<li>NotIn</li>
<li>Exists</li>
<li>DoesNotExist</li>
<li>Gt</li>
<li>Lt</li>
</ul>
<h3 id="node-affinity">Node Affinity</h3>
<p>Examine  the current pod distribution  </p>
<pre><code>kubectl get pods -o wide --selector=&quot;role=vote&quot;

</code></pre>

<pre><code>NAME                    READY     STATUS    RESTARTS   AGE       IP               NODE
vote-8546bbd84d-22d6x   1/1       Running   0          35s       10.233.102.137   node1
vote-8546bbd84d-8f9bc   1/1       Running   0          1m        10.233.102.136   node1
vote-8546bbd84d-bpg8f   1/1       Running   0          1m        10.233.75.12     node2
vote-8546bbd84d-d8j9g   1/1       Running   0          1m        10.233.75.13     node2
</code></pre>

<p>and node labels</p>
<pre><code>kubectl get nodes --show-labels

</code></pre>

<pre><code>NAME      STATUS    ROLES         AGE       VERSION   LABELS
node1     Ready     master,node   1d        v1.10.4   beta.kubernetes.io/arch=amd64,beta.kubernetes.io/os=linux,kubernetes.io/hostname=node1,node-role.kubernetes.io/master=true,node-role.kubernetes.io/node=true,zone=bbb
node2     Ready     master,node   1d        v1.10.4   beta.kubernetes.io/arch=amd64,beta.kubernetes.io/os=linux,kubernetes.io/hostname=node2,node-role.kubernetes.io/master=true,node-role.kubernetes.io/node=true,zone=bbb
node3     Ready     node          1d        v1.10.4   beta.kubernetes.io/arch=amd64,beta.kubernetes.io/os=linux,kubernetes.io/hostname=node3,node-role.kubernetes.io/node=true,zone=aaa
node4     Ready     node          1d        v1.10.4   beta.kubernetes.io/arch=amd64,beta.kubernetes.io/os=linux,kubernetes.io/hostname=node4,node-role.kubernetes.io/node=true,zone=aaa
</code></pre>

<p>Lets create node affinity criteria as</p>
<ul>
<li>Pods for vote app <strong>must</strong> not run on the master nodes</li>
<li>Pods for vote app <strong>preferably</strong> run on a node in zone <strong>bbb</strong></li>
</ul>
<p>First is a <strong>hard</strong> affinity versus second being <strong>soft</strong> affinity.</p>
<p><code>file: vote-deploy.yaml</code></p>
<pre><code>....
  template:
....
    spec:
      containers:
        - name: app
          image: schoolofdevops/vote:v1
          ports:
            - containerPort: 80
              protocol: TCP

      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
            - matchExpressions:
              - key: node-role.kubernetes.io/master
                operator: DoesNotExist
          preferredDuringSchedulingIgnoredDuringExecution:
            - weight: 1
              preference:
                matchExpressions:
                - key: zone
</code></pre>

<h3 id="pod-affinity">Pod Affinity</h3>
<p>Lets define pod affinity criteria as,</p>
<ul>
<li>Pods for <strong>vote</strong> and <strong>redis</strong> should be co located as much as possible (preferred)</li>
<li>No two pods with <strong>redis</strong> app should be running on the same node (required)</li>
</ul>
<pre><code>kubectl get pods -o wide --selector=&quot;role in (vote,redis)&quot;

</code></pre>

<p>[sample output]</p>
<pre><code>NAME                     READY     STATUS    RESTARTS   AGE       IP               NODE
redis-6555998885-4k5cr   1/1       Running   0          4h        10.233.71.19     node3
redis-6555998885-fb8rk   1/1       Running   0          4h        10.233.102.132   node1
vote-74c894d6f5-bql8z    1/1       Running   0          22m       10.233.74.78     node4
vote-74c894d6f5-nnzmc    1/1       Running   0          21m       10.233.71.22     node3
vote-74c894d6f5-ss929    1/1       Running   0          22m       10.233.74.77     node4
vote-74c894d6f5-tpzgm    1/1       Running   0          22m       10.233.71.21     node3
</code></pre>

<p><code>file: vote-deploy.yaml</code></p>
<pre><code>...
    template:
...
    spec:
      containers:
        - name: app
          image: schoolofdevops/vote:v1
          ports:
            - containerPort: 80
              protocol: TCP

      affinity:
...

        podAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            - weight: 1
              podAffinityTerm:
                labelSelector:
                  matchExpressions:
                  - key: role
                    operator: In
                    values:
                    - redis
                topologyKey: kubernetes.io/hostname
</code></pre>

<p><code>file: redis-deploy.yaml</code></p>
<pre><code>....
  template:
...
    spec:
      containers:
      - image: schoolofdevops/redis:latest
        imagePullPolicy: Always
        name: redis
        ports:
        - containerPort: 6379
          protocol: TCP
      restartPolicy: Always

      affinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchExpressions:
              - key: role
                operator: In
                values:
                - redis
            topologyKey: &quot;kubernetes.io/hostname&quot;
</code></pre>

<p>apply</p>
<pre><code>kubectl apply -f redis-deploy.yaml
kubectl apply -f vote-deploy.yaml

</code></pre>

<p>check the pods distribution</p>
<pre><code>kubectl get pods -o wide --selector=&quot;role in (vote,redis)&quot;
</code></pre>

<p>[sample output ]</p>
<pre><code>NAME                     READY     STATUS    RESTARTS   AGE       IP             NODE
redis-5bf748dbcf-gr8zg   1/1       Running   0          13m       10.233.75.14   node2
redis-5bf748dbcf-vxppx   1/1       Running   0          13m       10.233.74.79   node4
vote-56bf599b9c-22lpw    1/1       Running   0          12m       10.233.74.80   node4
vote-56bf599b9c-nvvfd    1/1       Running   0          13m       10.233.71.25   node3
vote-56bf599b9c-w6jc9    1/1       Running   0          13m       10.233.71.23   node3
vote-56bf599b9c-ztdgm    1/1       Running   0          13m       10.233.71.24   node3
</code></pre>

<p>Observations from the above output,</p>
<ul>
<li>Since redis has a hard constraint not to be on the same node, you would observe redis pods being on differnt nodes  (node2 and node4)</li>
<li>since vote app has a soft constraint, you see some of the pods running on node4 (same node running redis), others continue to run on node 3</li>
</ul>
<p>If you kill the pods on node3, at the time of  scheduling new ones, scheduler meets all affinity rules</p>
<pre><code>$ kubectl delete pods vote-56bf599b9c-nvvfd vote-56bf599b9c-w6jc9 vote-56bf599b9c-ztdgm
pod &quot;vote-56bf599b9c-nvvfd&quot; deleted
pod &quot;vote-56bf599b9c-w6jc9&quot; deleted
pod &quot;vote-56bf599b9c-ztdgm&quot; deleted


$ kubectl get pods -o wide --selector=&quot;role in (vote,redis)&quot;
NAME                     READY     STATUS    RESTARTS   AGE       IP             NODE
redis-5bf748dbcf-gr8zg   1/1       Running   0          19m       10.233.75.14   node2
redis-5bf748dbcf-vxppx   1/1       Running   0          19m       10.233.74.79   node4
vote-56bf599b9c-22lpw    1/1       Running   0          19m       10.233.74.80   node4
vote-56bf599b9c-4l6bc    1/1       Running   0          20s       10.233.74.83   node4
vote-56bf599b9c-bqsrq    1/1       Running   0          20s       10.233.74.82   node4
vote-56bf599b9c-xw7zc    1/1       Running   0          19s       10.233.74.81   node4
</code></pre>

<h2 id="taints-and-tolerations">Taints and tolerations</h2>
<ul>
<li>Affinity is defined for pods</li>
<li>Taints are defined for nodes</li>
</ul>
<p>You could add the taints with criteria and effects. Effetcs can be</p>
<p><strong>Taint Specs</strong>: <br />
  * effect
    * NoSchedule
    * PreferNoSchedule
    * NoExecute
  * key
  * value
  * timeAdded (only written for NoExecute taints)</p>
<p>Observe the pods distribution</p>
<pre><code>$ kubectl get pods -o wide
NAME                      READY     STATUS    RESTARTS   AGE       IP             NODE
db-66496667c9-qggzd       1/1       Running   0          4h        10.233.74.74   node4
redis-5bf748dbcf-gr8zg    1/1       Running   0          27m       10.233.75.14   node2
redis-5bf748dbcf-vxppx    1/1       Running   0          27m       10.233.74.79   node4
result-5c7569bcb7-4fptr   1/1       Running   0          4h        10.233.71.18   node3
result-5c7569bcb7-s4rdx   1/1       Running   0          4h        10.233.74.75   node4
vote-56bf599b9c-22lpw     1/1       Running   0          26m       10.233.74.80   node4
vote-56bf599b9c-4l6bc     1/1       Running   0          8m        10.233.74.83   node4
vote-56bf599b9c-bqsrq     1/1       Running   0          8m        10.233.74.82   node4
vote-56bf599b9c-xw7zc     1/1       Running   0          8m        10.233.74.81   node4
worker-7c98c96fb4-7tzzw   1/1       Running   1          4h        10.233.75.8    node2
</code></pre>

<p>Lets taint a node.</p>
<pre><code>kubectl taint node node2 dedicate=worker:NoExecute
</code></pre>

<p>after taining the node</p>
<pre><code>$ kubectl get pods -o wide
NAME                      READY     STATUS    RESTARTS   AGE       IP               NODE
db-66496667c9-qggzd       1/1       Running   0          4h        10.233.74.74     node4
redis-5bf748dbcf-ckn65    1/1       Running   0          2m        10.233.71.26     node3
redis-5bf748dbcf-vxppx    1/1       Running   0          30m       10.233.74.79     node4
result-5c7569bcb7-4fptr   1/1       Running   0          4h        10.233.71.18     node3
result-5c7569bcb7-s4rdx   1/1       Running   0          4h        10.233.74.75     node4
vote-56bf599b9c-22lpw     1/1       Running   0          29m       10.233.74.80     node4
vote-56bf599b9c-4l6bc     1/1       Running   0          11m       10.233.74.83     node4
vote-56bf599b9c-bqsrq     1/1       Running   0          11m       10.233.74.82     node4
vote-56bf599b9c-xw7zc     1/1       Running   0          11m       10.233.74.81     node4
worker-7c98c96fb4-46ltl   1/1       Running   0          2m        10.233.102.140   node1
</code></pre>

<p>All pods running on node2 just got evicted.</p>
<p>Add toleration in the Deployment for worker.</p>
<p><code>File: worker-deploy.yml</code></p>
<pre><code>apiVersion: apps/v1
.....
  template:
....
    spec:
      containers:
        - name: app
          image: schoolofdevops/vote-worker:latest

      tolerations:
        - key: &quot;dedicate&quot;
          operator: &quot;Equal&quot;
          value: &quot;worker&quot;
          effect: &quot;NoExecute&quot;
</code></pre>

<p>apply</p>
<pre><code>kubectl apply -f worker-deploy.yml

</code></pre>

<p>Observe the pod distribution now.</p>
<pre><code>$ kubectl get pods -o wide
NAME                      READY     STATUS    RESTARTS   AGE       IP             NODE
db-66496667c9-qggzd       1/1       Running   0          4h        10.233.74.74   node4
redis-5bf748dbcf-ckn65    1/1       Running   0          3m        10.233.71.26   node3
redis-5bf748dbcf-vxppx    1/1       Running   0          31m       10.233.74.79   node4
result-5c7569bcb7-4fptr   1/1       Running   0          4h        10.233.71.18   node3
result-5c7569bcb7-s4rdx   1/1       Running   0          4h        10.233.74.75   node4
vote-56bf599b9c-22lpw     1/1       Running   0          30m       10.233.74.80   node4
vote-56bf599b9c-4l6bc     1/1       Running   0          12m       10.233.74.83   node4
vote-56bf599b9c-bqsrq     1/1       Running   0          12m       10.233.74.82   node4
vote-56bf599b9c-xw7zc     1/1       Running   0          12m       10.233.74.81   node4
worker-6cc8dbd4f8-6bkfg   1/1       Running   0          1m        10.233.75.15   node2
</code></pre>

<p>You should see worker being scheduled on node2</p>
<p>To remove the taint created above</p>
<pre><code>kubectl taint node node2 dedicate:NoExecute-
</code></pre>
              
            </div>
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="../pod-adv-specs/" class="btn btn-neutral float-right" title="Pod Resource and Security Specs">Next <span class="icon icon-circle-arrow-right"></span></a>
      
      
        <a href="../configuring_authentication_and_authorization/" class="btn btn-neutral" title="Authentication and Authorization (RBAC)"><span class="icon icon-circle-arrow-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
    
  </div>

  Built with <a href="http://www.mkdocs.org">MkDocs</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
      
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" style="cursor: pointer">
    <span class="rst-current-version" data-toggle="rst-current-version">
      
      
        <span><a href="../configuring_authentication_and_authorization/" style="color: #fcfcfc;">&laquo; Previous</a></span>
      
      
        <span style="margin-left: 15px"><a href="../pod-adv-specs/" style="color: #fcfcfc">Next &raquo;</a></span>
      
    </span>
</div>
    <script>var base_url = '..';</script>
    <script src="../js/theme.js"></script>
      <script src="../search/require.js"></script>
      <script src="../search/search.js"></script>

</body>
</html>
